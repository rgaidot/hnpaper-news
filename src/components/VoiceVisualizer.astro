---
// VoiceVisualizer.astro
// Symmetric bar visualizer — bars grow from the vertical center outward.
// Reads --vv-accent CSS variable for color (fallback: currentColor).
---

<div class="vv-wrap" aria-hidden="true">
  <canvas id="voice-visualizer"></canvas>
</div>

<style>
  .vv-wrap {
    position: fixed;
    inset: 0;
    display: flex;
    align-items: center;
    justify-content: center;
    width: 100vw;
    height: 100vh;
    overflow: hidden;
    z-index: -5; /* Behind content but above the base background */
    pointer-events: none; /* Don't block clicks */
  }

  #voice-visualizer {
    display: block;
    width: 100%;
    height: 100%;
  }
</style>

<script>
  (function () {
    const canvas = document.getElementById('voice-visualizer') as HTMLCanvasElement | null;
    if (!canvas) return;
    const ctx = canvas.getContext('2d');
    if (!ctx) return;

    // ── Config ────────────────────────────────────────────────────────────
    const BAR_WIDTH_BASE = 4; // Target width in px (will be scaled by dpr)
    const BAR_GAP_BASE = 2;   // Target gap in px
    const BAR_RADIUS = 2;     // px radius for rounded corners
    const MIRRORED = true;    // Symmetric visualization
    
    // ── Audio pipeline ────────────────────────────────────────────────────
    let audioCtx: AudioContext | null = null;
    let analyser: AnalyserNode | null = null;
    let dataArray: Uint8Array | null = null;
    let animFrame: number | null = null;
    let isPlaying = false;
    let isSetup = false;

    function setup(audioEl: HTMLAudioElement) {
      if (isSetup) return;
      isSetup = true;
      audioCtx  = new AudioContext();
      analyser  = audioCtx.createAnalyser();
      // fftSize 2048 -> 1024 bins. Enough for full width high res.
      analyser.fftSize = 2048; 
      analyser.smoothingTimeConstant = 0.85;

      const source = audioCtx.createMediaElementSource(audioEl);
      source.connect(analyser);
      analyser.connect(audioCtx.destination);
      dataArray = new Uint8Array(analyser.frequencyBinCount);
    }

    // ── Canvas resize ─────────────────────────────────────────────────────
    function resize() {
      const dpr  = window.devicePixelRatio || 1;
      const rect = canvas!.getBoundingClientRect();
      canvas!.width  = rect.width  * dpr;
      canvas!.height = rect.height * dpr;
    }
    new ResizeObserver(resize).observe(canvas);
    resize();

    // ── Accent color ──────────────────────────────────────────────────────
    const ACCENT = 'oklch(0.768 0.233 130.85 / 0.4)'; 

    function accentColor(): string {
      return ACCENT;
    }

    // ── Draw ──────────────────────────────────────────────────────────────
    function drawFrame() {
      const dpr  = window.devicePixelRatio || 1;
      const W    = canvas!.width;
      const H    = canvas!.height;
      const midY = H / 2;

      ctx!.clearRect(0, 0, W, H);
      
      const color = accentColor();
      ctx!.fillStyle = color;

      const barWidth = BAR_WIDTH_BASE * dpr;
      const barGap = BAR_GAP_BASE * dpr;
      
      // Calculate how many bars fit in the width
      const totalWidthPerBar = barWidth + barGap;
      const maxBars = Math.floor(W / totalWidthPerBar);
      
      // For mirrored: we need an even number of bars
      // effectively 'binsToUse' = maxBars / 2
      let binsToUse = Math.floor(maxBars / (MIRRORED ? 2 : 1));
      // Cap binsToUse to available frequency data (usually 1024)
      // We limit to ~120-150 effectively for voice range usually, but let's fill screen.
      // If screen is huge, we might stretch the low frequency range too much.
      // Let's just use what we have.
      
      const totalBars = MIRRORED ? binsToUse * 2 : binsToUse;
      const actualTotalWidth = totalBars * totalWidthPerBar - barGap;
      const startX = (W - actualTotalWidth) / 2;

      if (!isPlaying || !analyser || !dataArray) {
        // Idle state
        for (let i = 0; i < totalBars; i++) {
            const h = 4 * dpr;
            const x = startX + i * totalWidthPerBar;
            const y = midY - h/2;
            
            if (ctx!.roundRect) {
                ctx!.beginPath();
                ctx!.roundRect(x, y, barWidth, h, BAR_RADIUS * dpr);
                ctx!.fill();
            } else {
                ctx!.fillRect(x, y, barWidth, h);
            }
        }
        return;
      }

      analyser.getByteFrequencyData(dataArray);

      // We want to map 'binsToUse' bars to the useful frequency range.
      // Voice is mostly 0-4kHz. 
      // With 44.1kHz sample rate, 1024 bins cover 0-22kHz.
      // So 0-4kHz is roughly the first 20% of bins (~200 bins).
      // If we have more bars than 200, we might need to interpolate or just show higher freqs (noise).
      // If we have fewer bars, we skip bins.
      
      // Let's focus on the first ~300 bins for better visuals.
      const usefulBins = 300; 

      for (let i = 0; i < binsToUse; i++) {
        // Map bar index 'i' to frequency index
        const freqIndex = Math.floor(i * (usefulBins / binsToUse));
        
        // Safety check
        const safeIndex = Math.min(freqIndex, dataArray.length - 1);
        
        // Boost high frequencies slightly
        const boost = 1 + (i / binsToUse) * 0.8;
        const val = Math.min(255, dataArray[safeIndex] * boost);
        
        const h = Math.max(4 * dpr, (val / 255) * (H * 0.6)); 
        const y = midY - h/2;

        if (MIRRORED) {
            // Draw Left (going outwards from center? Or mirrored left/right side?)
            // "Symmetric bar visualizer — bars grow from the vertical center outward"
            // Usually means low freqs in center, high freqs at edges.
            
            // Left side: index goes from center (binsToUse-1) down to 0 ? 
            // Or 0 at far left?
            // If low freqs are center:
            // Center is between binsToUse-1 and binsToUse.
            
            const leftIndex = binsToUse - 1 - i; 
            const xLeft = startX + leftIndex * totalWidthPerBar;
            
            if (ctx!.roundRect) {
                 ctx!.beginPath();
                 ctx!.roundRect(xLeft, y, barWidth, h, BAR_RADIUS * dpr);
                 ctx!.fill();
            } else {
                 ctx!.fillRect(xLeft, y, barWidth, h);
            }

            // Right side
            const rightIndex = binsToUse + i;
            const xRight = startX + rightIndex * totalWidthPerBar;

             if (ctx!.roundRect) {
                 ctx!.beginPath();
                 ctx!.roundRect(xRight, y, barWidth, h, BAR_RADIUS * dpr);
                 ctx!.fill();
            } else {
                 ctx!.fillRect(xRight, y, barWidth, h);
            }
        } else {
             // Linear
             const x = startX + i * totalWidthPerBar;
             if (ctx!.roundRect) {
                 ctx!.beginPath();
                 ctx!.roundRect(x, y, barWidth, h, BAR_RADIUS * dpr);
                 ctx!.fill();
            } else {
                 ctx!.fillRect(x, y, barWidth, h);
            }
        }
      }
    }

    // ── Animation loop ────────────────────────────────────────────────────
    function loop() {
      drawFrame();
      animFrame = requestAnimationFrame(loop);
    }

    loop();

    // ── State control ─────────────────────────────────────────────────────
    function onPlay(audioEl: HTMLAudioElement) {
      setup(audioEl);
      if (audioCtx?.state === 'suspended') audioCtx.resume();
      isPlaying = true;
    }

    function onStop() {
      isPlaying = false;
    }

    // ── Attach to audio element ───────────────────────────────────────────
    function attach(audioEl: HTMLAudioElement) {
      audioEl.addEventListener('play',  () => onPlay(audioEl));
      audioEl.addEventListener('pause', onStop);
      audioEl.addEventListener('ended', onStop);
    }

    const existing = document.getElementById('audio-player') as HTMLAudioElement | null;
    if (existing) {
      attach(existing);
    } else {
      const mo = new MutationObserver(() => {
        const el = document.getElementById('audio-player') as HTMLAudioElement | null;
        if (el) { attach(el); mo.disconnect(); }
      });
      mo.observe(document.body, { childList: true, subtree: true });
    }

    window.addEventListener('tts:state-changed', (e: Event) => {
      const { state } = (e as CustomEvent).detail;
      const audioEl   = document.getElementById('audio-player') as HTMLAudioElement | null;
      if (!audioEl) return;
      if (state === 'playing') onPlay(audioEl);
      else onStop();
    });
  })();
</script>
